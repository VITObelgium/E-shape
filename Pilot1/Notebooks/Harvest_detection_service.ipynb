{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4230da83",
   "metadata": {},
   "source": [
    "### Installing openEO client libraries\n",
    "\n",
    "To use openEO, you need to make sure that the openEO client libraries are installed. The library is available on pypi, so it can be installed with pip: \n",
    "https://pypi.org/project/openeo/\n",
    "\n",
    "We recommend using at least Python 3.6 so in the notebook environment, the install command is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f086986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://artifactory.vgt.vito.be/api/pypi/python-packages/simple\n",
      "Requirement already satisfied: openeo in /home/bontek/.local/lib/python3.6/site-packages (0.9.2)\n",
      "Requirement already satisfied: deprecated>=1.2.12 in /usr/local/lib64/python3.6/site-packages (from openeo) (1.2.13)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/bontek/.local/lib/python3.6/site-packages (from openeo) (2.26.0)\n",
      "Requirement already satisfied: pandas>0.20.0; python_version >= \"3.5.3\" in /usr/local/lib64/python3.6/site-packages (from openeo) (0.25.1)\n",
      "Requirement already satisfied: xarray>=0.12.3 in /usr/local/lib/python3.6/site-packages (from openeo) (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib64/python3.6/site-packages (from openeo) (1.17.1)\n",
      "Requirement already satisfied: shapely>=1.6.4 in /usr/local/lib64/python3.6/site-packages (from openeo) (1.6.4.post2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib64/python3.6/site-packages (from deprecated>=1.2.12->openeo) (1.11.2)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/local/lib/python3.6/site-packages (from requests>=2.26.0->openeo) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests>=2.26.0->openeo) (2019.6.16)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bontek/.local/lib/python3.6/site-packages (from requests>=2.26.0->openeo) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/bontek/.local/lib/python3.6/site-packages (from requests>=2.26.0->openeo) (2.0.9)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas>0.20.0; python_version >= \"3.5.3\"->openeo) (2019.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/bontek/.local/lib/python3.6/site-packages (from pandas>0.20.0; python_version >= \"3.5.3\"->openeo) (2.7.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas>0.20.0; python_version >= \"3.5.3\"->openeo) (1.12.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3.6 install --user openeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "626e9622",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading of the required functions \n",
    "\n",
    "import openeo\n",
    "import json\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea10f64",
   "metadata": {},
   "source": [
    "### Create openeo session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d82173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    }
   ],
   "source": [
    "endpoint = os.environ.get(\"ENDPOINT\", \"https://openeo-dev.vito.be\")\n",
    "openeo_url = \"{e}/openeo/{v}\".format(e=endpoint, v=\"1.0.0\") \n",
    "openeo_session = openeo.connect(openeo_url).authenticate_oidc(provider_id=\"egi\") # The first time you will try to connect to openeo you will need to link your Terrascope account to EGI credentials. Follow the procedure list below to allow this. \n",
    "#if you want more info, please consult: https://docs.terrascope.be/#/Developers/WebServices/OpenEO/OpenEO?id=logging-in "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4202c2",
   "metadata": {},
   "source": [
    "### Description on about the harvest detection service\n",
    "\n",
    "### Crop calendar (harvest prediction)\n",
    "The CropCalendar service is used to automatically predict harvest dates from a set of input geometries. The harvest date prediction is written in an additional attribute table of the input geometry collection. The output of the service is a geojson format of all the input geometries including the harvest date as an addtional column.\n",
    "\n",
    "### Methodology\n",
    "A trained neural network model is used to automatically predict harvest dates based on input timeseries of Sentinel data. Both timeseries generated from **Sentinel-1 and Sentinel-2** are used to ingest in the model, more specifically the **VH/VV** ratio and the **daily fAPAR** (from CropSAR) are used. The model is only trained on detecting the moment the **above ground biomass** is removed from the field. \n",
    "\n",
    "### Quality\n",
    "The model was trained on field data from Belgium with a focus on potato, maize and flax. Overall, the harvest date could be detected within **5-6 days accurate** based on validation of some reference fields in Italy (sugarbeet and soybean). However, it can be expected that for certain crop types and areas with different field management around harvest the performance might be less accurate. Furthermore, if the harvest of a certain crop does not match with the removal of all above ground biomass, the harvest detector will detect the acutal removal of all biomass. This is for example the case for cotton.\n",
    "\n",
    "### Disclaimer\n",
    "The time range parameter should span more than 2 months and preferably centered around the expected harvest date otherwise the performance will drop. Requesting harvest date prediction in near-real time modus is not yet supported. The input geometries should be larger than 20x20 m since a 10m inwards buffer is automatically taken to minimize boundary contamination in the timeseries.\n",
    "\n",
    "### Links\n",
    "For a more detailed description of the algorithm, please consult:\n",
    "\n",
    "[Link]https://blog.vito.be/remotesensing/what-happens-on-the-fields-monitoring-the-crop-calendars\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd5e948",
   "metadata": {},
   "source": [
    "### Required parameters\n",
    "\n",
    "* **date**: The period for which satellite data should be retrieved and used to estimate harvest date(s)\n",
    "  * e.g. \"2017-01-01\",\"2019-12-31\".  \n",
    "* **polygon**: Featurecollection of polygons for which harvest should be estimated\n",
    "\n",
    "### Output\n",
    "The output of the service is a GEOJSON object with all the harvest date(s) that are detected for each field. \n",
    "The labels of the fields are used to assign the harvest date(s) to. In case no harvest event could be detected, it is set to 'None'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84eb0749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bontek/.local/lib/python3.6/site-packages/openeo/metadata.py:240: UserWarning: No cube:dimensions metadata\n",
      "  complain(\"No cube:dimensions metadata\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job '9b820d0c-68e3-4fd5-9180-ca5d47125c59': send 'start'\n",
      "0:01:09 Job '9b820d0c-68e3-4fd5-9180-ca5d47125c59': queued (progress N/A)\n",
      "0:01:14 Job '9b820d0c-68e3-4fd5-9180-ca5d47125c59': queued (progress N/A)\n",
      "0:01:21 Job '9b820d0c-68e3-4fd5-9180-ca5d47125c59': queued (progress N/A)\n",
      "0:01:29 Job '9b820d0c-68e3-4fd5-9180-ca5d47125c59': queued (progress N/A)\n",
      "0:01:39 Job '9b820d0c-68e3-4fd5-9180-ca5d47125c59': queued (progress N/A)\n",
      "0:01:52 Job '9b820d0c-68e3-4fd5-9180-ca5d47125c59': queued (progress N/A)\n",
      "0:02:08 Job '9b820d0c-68e3-4fd5-9180-ca5d47125c59': queued (progress N/A)\n",
      "0:02:27 Job '9b820d0c-68e3-4fd5-9180-ca5d47125c59': running (progress N/A)\n",
      "0:02:51 Job '9b820d0c-68e3-4fd5-9180-ca5d47125c59': running (progress N/A)\n",
      "0:03:22 Job '9b820d0c-68e3-4fd5-9180-ca5d47125c59': running (progress N/A)\n",
      "0:04:00 Job '9b820d0c-68e3-4fd5-9180-ca5d47125c59': running (progress N/A)\n",
      "0:04:47 Job '9b820d0c-68e3-4fd5-9180-ca5d47125c59': running (progress N/A)\n",
      "0:05:46 Job '9b820d0c-68e3-4fd5-9180-ca5d47125c59': running (progress N/A)\n",
      "0:06:46 Job '9b820d0c-68e3-4fd5-9180-ca5d47125c59': running (progress N/A)\n",
      "0:07:47 Job '9b820d0c-68e3-4fd5-9180-ca5d47125c59': finished (progress N/A)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:33: DeprecationWarning: Call to deprecated method get_result. (Use `RESTJob.get_results` instead.) -- Deprecated since version 0.4.10.\n"
     ]
    }
   ],
   "source": [
    "# Define input parameters\n",
    " \n",
    "time_range = \"2020-01-31\", \"2020-12-31\"\n",
    "\n",
    "# now we only need to still specify the polygons for which the predictions should be made\n",
    "# please first upload the geometry files to the Private/Public folder in the notebook environment!\n",
    "\n",
    "ID_identifier = 'id' # the column name of the input geometries files that contains the unique names of the fields. \n",
    "base_public_folder = os.path.join('/data', 'users', 'Public', os.environ['USER']) # use the public folder to store the input geometries so that they can be loaded from there\n",
    "output_folder = 'Harvest_output_fields_demo' # name of the subfolder in the working directory that will be used to store the results\n",
    "os.makedirs(os.path.join(os.getcwd(), output_folder), exist_ok = True)\n",
    "\n",
    "\n",
    "file_geom_path = r'Public/e_shape/Notebooks/test_fields/test_fields_WIG2020_3_fields.shp' #Copy the file path from the available shapefile(s) on the left side of the screen. Do this by right clicking on the file and click on 'Copy Path'\n",
    "file_geom_path = file_geom_path.replace('Public/','') # remove redundant Public name in directory\n",
    "full_geom_path = os.path.join(base_public_folder, file_geom_path)\n",
    "\n",
    "# now that we have the path, the shapefile can be loaded and coverted to the desired format to send to openEO\n",
    "gpd_shp = gpd.read_file(full_geom_path)\n",
    "field_ids = gpd_shp[ID_identifier].to_list()\n",
    "polygons = json.loads(gpd_shp.to_json()) # Mandatory parameter\n",
    "\n",
    "Harvest_process = openeo_session.datacube_from_process(\"CropCalendar\", namespace=\"https://openeo-dev.vito.be/openeo/1.0/processes/u:bontek/CropCalendar\"\n",
    "                                                         , date=time_range ,polygon = polygons) #create the process graph for the service\n",
    "\n",
    "\n",
    "#print(Harvest_process.graph)\n",
    "\n",
    "\n",
    "# Obtain result\n",
    "\n",
    "### option 1 -> When executing for many fields over a long time period (do asynchronous call)\n",
    "Harvest_result = Harvest_process.send_job().start_and_wait().get_result().load_json() # # once the job is launched it will take a while before you will get the result so wait until in the screen  below the message 'finished' pops-up. First you will see 'queued' -> 'running' -> 'finished'\n",
    "    # in case the message is 'error' -> Please try again to run the job once again, if still fails please reach out.  \n",
    "\n",
    "### option 2 -> When executing for only few fields and for a short time period, a synchronous call can be done which is quite fast\n",
    "\n",
    "#Harvest_result = Harvest_process.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8276a70d",
   "metadata": {},
   "source": [
    "### Store the output result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7b8c1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Harvest_date\n",
      "AW_wZ9XOQA72oZUZfVrl         None\n",
      "AW_waRfcNgS9FFefG0bM         None\n",
      "AW_waDXzQA72oZUZfVrr         None\n"
     ]
    }
   ],
   "source": [
    "Harvest_dates = []\n",
    "for field in Harvest_result['features']:\n",
    "    harvest_field = field['properties']['Harvest_date']\n",
    "    Harvest_dates.append(harvest_field)\n",
    "    \n",
    "df_harv_result = pd.DataFrame(data = Harvest_dates, index = field_ids, columns = ['Harvest_date'])     \n",
    "df_harv_result.to_csv('Harv_result.csv', index = True) # This stores the CSV file in the same folder as the notebook is stored\n",
    "print(df_harv_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
