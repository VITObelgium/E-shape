{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c18a820",
   "metadata": {},
   "source": [
    "### Installing openEO client libraries\n",
    "\n",
    "To use openEO, you need to make sure that the openEO client libraries are installed. The library is available on pypi, so it can be installed with pip: \n",
    "https://pypi.org/project/openeo/\n",
    "\n",
    "We recommend using at least Python 3.6 so in the notebook environment, the install command is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4017a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://artifactory.vgt.vito.be/api/pypi/python-packages/simple\n",
      "Requirement already satisfied: openeo in /home/bontek/.local/lib/python3.6/site-packages (0.9.2)\n",
      "Requirement already satisfied: deprecated>=1.2.12 in /usr/local/lib64/python3.6/site-packages (from openeo) (1.2.13)\n",
      "Requirement already satisfied: shapely>=1.6.4 in /usr/local/lib64/python3.6/site-packages (from openeo) (1.6.4.post2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib64/python3.6/site-packages (from openeo) (1.17.1)\n",
      "Requirement already satisfied: pandas>0.20.0; python_version >= \"3.5.3\" in /usr/local/lib64/python3.6/site-packages (from openeo) (0.25.1)\n",
      "Requirement already satisfied: xarray>=0.12.3 in /usr/local/lib/python3.6/site-packages (from openeo) (0.12.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/bontek/.local/lib/python3.6/site-packages (from openeo) (2.26.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib64/python3.6/site-packages (from deprecated>=1.2.12->openeo) (1.11.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas>0.20.0; python_version >= \"3.5.3\"->openeo) (2019.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/bontek/.local/lib/python3.6/site-packages (from pandas>0.20.0; python_version >= \"3.5.3\"->openeo) (2.7.5)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/bontek/.local/lib/python3.6/site-packages (from requests>=2.26.0->openeo) (2.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests>=2.26.0->openeo) (2019.6.16)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/local/lib/python3.6/site-packages (from requests>=2.26.0->openeo) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bontek/.local/lib/python3.6/site-packages (from requests>=2.26.0->openeo) (1.26.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas>0.20.0; python_version >= \"3.5.3\"->openeo) (1.12.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3.6 install --user openeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7adffade",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading of the required functions \n",
    "\n",
    "import openeo\n",
    "import json\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59276ebd",
   "metadata": {},
   "source": [
    "### Create openeo session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cd49391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OIDC token response did not contain refresh token.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    }
   ],
   "source": [
    "endpoint = os.environ.get(\"ENDPOINT\", \"https://openeo.vito.be\")\n",
    "openeo_url = \"{e}/openeo/{v}\".format(e=endpoint, v=\"1.0.0\") \n",
    "openeo_session = openeo.connect(openeo_url).authenticate_oidc(provider_id=\"egi\") # The first time you will try to connect to openeo you will need to link your Terrascope account to EGI credentials. Follow the procedure list below to allow this. \n",
    "#if you want more info, please consult: https://docs.terrascope.be/#/Developers/WebServices/OpenEO/OpenEO?id=logging-in "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943607b4",
   "metadata": {},
   "source": [
    "### Description on about the harvest detection service\n",
    "\n",
    "### Harvest detector summary\n",
    "The **Harvest detector** service is used to automatically predict harvest dates from a set of input geometries. The harvest date prediction gives per field the amount of harvest events within the requested time period. \n",
    "\n",
    "\n",
    "### Methodology\n",
    "A trained neural network model is used to automatically predict harvest dates based on input timeseries of Sentinel data. Both timeseries generated from **Sentinel-1 and Sentinel-2** are used to ingest in the model, more specifically the **VH/VV ratio**, the **daily fAPAR (from CropSAR)**  and a **Sentinel-2 metric sensitive to crop residue(NBR2)** are used. The model is only trained on detecting the moment the **above ground biomass** is removed from the field. \n",
    "\n",
    "### Quality\n",
    "The model was trained on field data from Belgium, Italy & Greece with a focus on potato, maize and flax and cover crops. Overall, the harvest date could be detected within 10 days accurate based on validation of some reference fields, but for cover crops the uncertainty may be somewhat larger.\n",
    "However, it can be expected that for certain crop types and areas with different field management around harvest the performance might be less accurate.\n",
    "Furthermore, if the harvest of a certain crop does not match with the removal of all above ground biomass, the harvest detector will detect the actual removal of all biomass. This is for example the case for cotton.\n",
    "\n",
    "### Disclaimer\n",
    "The time range parameter should span more than 2 months and preferably centered around the expected harvest date otherwise the performance will drop.\n",
    "Requesting harvest date prediction in near-real time modus is not yet supported.\n",
    "The users must **inwards buffer** their geometries beforehand to reduce the risk of including to match noise into the timeseries.\n",
    "The buffered geometries should be larger than 20x20 m.\n",
    "\n",
    "### Links\n",
    "\n",
    "For a more detailed description on the fundaments of the approach, please consult:\n",
    "\n",
    "[Link]https://blog.vito.be/remotesensing/what-happens-on-the-fields-monitoring-the-crop-calendars\"\n",
    "\n",
    "### Version \n",
    "Version from October 2022 based on the work for E-shape by the addition of cover crops in the model training by making use of the in-situ data collected by the CropObserve app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc978528",
   "metadata": {},
   "source": [
    "### Required parameters\n",
    "\n",
    "* **date**: The period for which satellite data should be retrieved and used to estimate harvest date(s)\n",
    "  * e.g. \"2017-01-01\",\"2019-12-31\".  \n",
    "* **polygon**: Featurecollection of polygons for which harvest should be estimated\n",
    "\n",
    "### Output\n",
    "\n",
    "The output of the service is a JSON format with all the harvest date(s) that are detected for each field.In case no harvest event could be detected, it is set to 'None'. Each field will get a unique label in the outut JSON, based on the order the input fields are read when opening the GEOJSON file. For example, the harvest date of the first read field can be found in the JSON under the key 'Field_0' as Python starts counting by zero. For the next field it can be found under key 'Field_1' etc. (see example further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c13bda7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bontek/.local/lib/python3.6/site-packages/openeo/metadata.py:240: UserWarning: No cube:dimensions metadata\n",
      "  complain(\"No cube:dimensions metadata\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job 'j-8e428dc60f1b4ada988e801e81015453': send 'start'\n",
      "0:00:31 Job 'j-8e428dc60f1b4ada988e801e81015453': queued (progress N/A)\n",
      "0:00:36 Job 'j-8e428dc60f1b4ada988e801e81015453': queued (progress N/A)\n",
      "0:00:43 Job 'j-8e428dc60f1b4ada988e801e81015453': queued (progress N/A)\n",
      "0:00:51 Job 'j-8e428dc60f1b4ada988e801e81015453': queued (progress N/A)\n",
      "0:01:01 Job 'j-8e428dc60f1b4ada988e801e81015453': queued (progress N/A)\n",
      "0:01:14 Job 'j-8e428dc60f1b4ada988e801e81015453': queued (progress N/A)\n",
      "0:01:30 Job 'j-8e428dc60f1b4ada988e801e81015453': running (progress N/A)\n",
      "0:01:49 Job 'j-8e428dc60f1b4ada988e801e81015453': running (progress N/A)\n",
      "0:02:14 Job 'j-8e428dc60f1b4ada988e801e81015453': running (progress N/A)\n",
      "0:02:44 Job 'j-8e428dc60f1b4ada988e801e81015453': running (progress N/A)\n",
      "0:03:22 Job 'j-8e428dc60f1b4ada988e801e81015453': running (progress N/A)\n",
      "0:04:09 Job 'j-8e428dc60f1b4ada988e801e81015453': running (progress N/A)\n",
      "0:05:07 Job 'j-8e428dc60f1b4ada988e801e81015453': running (progress N/A)\n",
      "0:06:08 Job 'j-8e428dc60f1b4ada988e801e81015453': running (progress N/A)\n",
      "0:07:09 Job 'j-8e428dc60f1b4ada988e801e81015453': running (progress N/A)\n",
      "0:08:09 Job 'j-8e428dc60f1b4ada988e801e81015453': running (progress N/A)\n",
      "0:09:10 Job 'j-8e428dc60f1b4ada988e801e81015453': running (progress N/A)\n",
      "0:10:10 Job 'j-8e428dc60f1b4ada988e801e81015453': running (progress N/A)\n",
      "0:11:11 Job 'j-8e428dc60f1b4ada988e801e81015453': running (progress N/A)\n",
      "0:12:11 Job 'j-8e428dc60f1b4ada988e801e81015453': running (progress N/A)\n",
      "0:13:12 Job 'j-8e428dc60f1b4ada988e801e81015453': running (progress N/A)\n",
      "0:14:12 Job 'j-8e428dc60f1b4ada988e801e81015453': finished (progress N/A)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:33: DeprecationWarning: Call to deprecated method get_result. (Use `RESTJob.get_results` instead.) -- Deprecated since version 0.4.10.\n"
     ]
    }
   ],
   "source": [
    "# Define input parameters\n",
    " \n",
    "time_range = \"2021-10-31\", \"2022-05-18\"\n",
    "\n",
    "# now we only need to still specify the polygons for which the predictions should be made\n",
    "# please first upload the geometry files to the Private/Public folder in the notebook environment!\n",
    "\n",
    "ID_identifier = 'OBJECTID' # the column name of the input geometries files that contains the unique names of the fields. \n",
    "base_public_folder = os.path.join('/data', 'users', 'Public', os.environ['USER']) # use the public folder to store the input geometries so that they can be loaded from there\n",
    "output_folder = 'Harvest_output_fields_demo' # name of the subfolder in the working directory that will be used to store the results\n",
    "os.makedirs(os.path.join(os.getcwd(), output_folder), exist_ok = True)\n",
    "\n",
    "\n",
    "file_geom_path = r'Public/e_shape/Notebooks/test_fields/test_fields.shp' #Copy the file path from the available shapefile(s) on the left side of the screen. Do this by right clicking on the file and click on 'Copy Path'\n",
    "file_geom_path = file_geom_path.replace('Public/','') # remove redundant Public name in directory\n",
    "full_geom_path = os.path.join(base_public_folder, file_geom_path)\n",
    "\n",
    "# now that we have the path, the shapefile can be loaded and coverted to the desired format to send to openEO\n",
    "gpd_shp = gpd.read_file(full_geom_path)\n",
    "field_ids = gpd_shp[ID_identifier].to_list()\n",
    "polygons = json.loads(gpd_shp.to_json()) # Mandatory parameter\n",
    "\n",
    "Harvest_process = openeo_session.datacube_from_process(\"Harvest_detector\", namespace=\"https://openeo.vito.be/openeo/1.0/processes/u:bontek/Harvest_detector\"\n",
    "                                                         , date=time_range ,polygon = polygons) #create the process graph for the service\n",
    "\n",
    "\n",
    "#print(Harvest_process.graph)\n",
    "\n",
    "\n",
    "# Obtain result\n",
    "\n",
    "### option 1 -> When executing for many fields over a long time period (do asynchronous call)\n",
    "Harvest_result = Harvest_process.send_job().start_and_wait().get_result().load_json() # # once the job is launched it will take a while before you will get the result so wait until in the screen  below the message 'finished' pops-up. First you will see 'queued' -> 'running' -> 'finished'\n",
    "    # in case the message is 'error' -> Please try again to run the job once again, if still fails please reach out.  \n",
    "\n",
    "### option 2 -> When executing for only few fields and for a short time period, a synchronous call can be done which is quite fast\n",
    "\n",
    "#Harvest_result = Harvest_process.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3717d7b5",
   "metadata": {},
   "source": [
    "### Store the output result\n",
    "\n",
    "Below the link between the predicted harvest date and the field ids will be made again. \n",
    "The index of dataframe contains the ID of the field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb0488dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Harvest_date\n",
      "318575  [2022-03-30]\n",
      "330692            []\n",
      "76880   [2022-02-28]\n",
      "162529  [2022-04-17]\n",
      "227385  [2022-03-06]\n",
      "328898  [2022-04-11]\n",
      "433449  [2022-03-06]\n",
      "436653  [2022-04-17]\n",
      "472259            []\n",
      "477289  [2022-03-18]\n",
      "575251  [2022-01-23]\n",
      "560832  [2022-02-04]\n"
     ]
    }
   ],
   "source": [
    "Harvest_dates = []\n",
    "for field in Harvest_result.keys():\n",
    "    harvest_field = Harvest_result.get(field)\n",
    "    if not harvest_field:\n",
    "        harvest_field = [None]\n",
    "    Harvest_dates.append(harvest_field)\n",
    "    \n",
    "df_harv_result = pd.DataFrame(data = Harvest_dates, index = field_ids, columns = ['Harvest_date'])     \n",
    "df_harv_result.to_csv('Harv_result.csv', index = True) # This stores the CSV file in the same folder as the notebook is stored\n",
    "print(df_harv_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
